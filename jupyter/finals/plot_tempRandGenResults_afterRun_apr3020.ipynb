{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if saving and everything else has been correctly done after run the script for prestim later none filter on eCortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import cross_val_multiscore, LinearModel, GeneralizingEstimator, Scaler, \\\n",
    "                         Vectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, StratifiedShuffleSplit, \\\n",
    "                                    RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import argparse\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments:\n",
    "    def __init__(self, cond_block, cond_decoding, applyBaseline_bool, mtdt_feat, occ_channels):\n",
    "        self.cond_block = cond_block #'later' #{early,later}\n",
    "        self.cond_decoding = cond_decoding #'removeevoked' #{none,removeevoked,resampled}\n",
    "        self.applyBaseline_bool = applyBaseline_bool #'False'\n",
    "        self.mtdt_feat = mtdt_feat\n",
    "        self.occ_channels = occ_channels\n",
    "        \n",
    "        self.SAVE_EPOCH_ROOT = '../../../data/version5.2/preprocessed/epochs/aft_ICA_rej'\n",
    "        self.SAVE_RESULT_ROOT = '../../../results/temp_gen/blanca/'\n",
    "        self.cond_filter ='none' # {none,non_symm}\n",
    "        self.cond_time = 'prestim' #{prestim,poststim}\n",
    "        self.subj_num = 1\n",
    "        self.pre_tmin = -0.4\n",
    "        self.pre_tmax = 0.05\n",
    "        self.post_tmin = 0.05\n",
    "        self.post_tmax = 0.45\n",
    "        self.num_classes = 2\n",
    "        self.normalization_type = 'normal'# {normal,lstmPaper}\n",
    "        self.gen_rand_perm = 0\n",
    "        self.null_max_iter = 10000\n",
    "        self.loop_null_iter = 5\n",
    "        self.gen_decoder_scores = 1\n",
    "        self.random_state = 42 \n",
    "        self.max_iter = 10000\n",
    "        self.n_jobs = 1\n",
    "        self.scoring = 'roc_auc'\n",
    "        self.n_splits = '_3k'\n",
    "        print(self.SAVE_RESULT_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class arguments:\n",
    "#     def __init__(self, cond_block, cond_decoding, applyBaseline_bool, n_splits):\n",
    "#         self.cond_block = cond_block #'later' #{early,later}\n",
    "#         self.cond_decoding = cond_decoding #'removeevoked' #{none,removeevoked,resampled}\n",
    "#         self.applyBaseline_bool = applyBaseline_bool #'False'\n",
    "#         self.n_splits = n_splits#100\n",
    "\n",
    "#         self.SAVE_EPOCH_ROOT = '../../data/version5.2/preprocessed/epochs/aft_ICA_rej/'\n",
    "#         self.SAVE_RESULT_ROOT = '../../results/temp_gen/eCortex/'\n",
    "#         self.cond_filter ='none' # {none,non_symm}\n",
    "#         self.cond_time = 'prestim' #{prestim,poststim}\n",
    "#         self.subj_num = 1\n",
    "#         self.pre_tmin = -0.4\n",
    "#         self.pre_tmax = 0.05\n",
    "#         self.post_tmin = 0.05\n",
    "#         self.post_tmax = 0.45\n",
    "#         self.num_classes = 2\n",
    "#         self.normalization_type = 'normal'# {normal,lstmPaper}\n",
    "#         self.gen_rand_perm = 0\n",
    "#         self.null_max_iter = 10000\n",
    "#         self.loop_null_iter = 5\n",
    "#         self.gen_decoder_scores = 1\n",
    "#         self.random_state = 42 \n",
    "#         self.max_iter = 10000\n",
    "#         self.n_jobs = 1\n",
    "#         self.scoring = 'roc_auc'\n",
    "#         self.folder='noneFilter_PrePost_decod%s_bsline%s%s/' %(cond_decoding, \\\n",
    "#                                                        applyBaseline_bool, \\\n",
    "#                                                        n_splits)\n",
    "#         self.SAVE_RESULT_ROOT = self.SAVE_RESULT_ROOT + self.folder\n",
    "#         print(self.SAVE_RESULT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading and preparing epoch data to create each 4 grous and 2 pattern\n",
    "\"\"\"\n",
    "def read_prep_epochs(args):\n",
    "    if args.applyBaseline_bool:\n",
    "        filename_epoch = args.SAVE_EPOCH_ROOT + \\\n",
    "                         'epochs_sec_applyBaseline_subj%s-afterRejICA-epo.fif' \\\n",
    "                          %args.subj_num\n",
    "    else:\n",
    "        filename_epoch = args.SAVE_EPOCH_ROOT + \\\n",
    "                         'epochs_sec_subj%s-afterRejICA-epo.fif' \\\n",
    "                         %args.subj_num\n",
    "    epochs_orig = mne.read_epochs(filename_epoch, proj=True, preload=True,\n",
    "                                  verbose=None)\n",
    "    epochs = epochs_orig.copy()\n",
    "    subset = epochs['pred']['non'].copy()\n",
    "    subset = subset.pick_types(eeg=True)\n",
    "    if (args.cond_decoding=='removeevoked'):\n",
    "        # REMOVE EVOKED RESP.\n",
    "        subset.subtract_evoked()    # remove evoked response\n",
    "    elif (args.cond_decoding=='resampled'):\n",
    "        # RESAMPLE\n",
    "        subset = subset.resample(args.n_resampling, npad='auto')\n",
    "    else:\n",
    "        pass\n",
    "    ##==========================================================================\n",
    "    if subset['Block==7'].metadata.Ptrn_Type.values.shape[0]>0:\n",
    "       main_ptrn = subset['Block==7'].metadata.Ptrn_Type.values[0]\n",
    "    else:\n",
    "       main_ptrn = subset['Block==8'].metadata.Ptrn_Type.values[0]\n",
    "    ##==========================================================================\n",
    "    if args.cond_block=='early': #block 3-6\n",
    "        subset = subset['Block<7'].copy()\n",
    "        subset = subset['Block>2'].copy()\n",
    "    elif args.cond_block=='later':#block 7-10\n",
    "        subset = subset['Block<11'].copy()\n",
    "        subset = subset['Block>6'].copy()\n",
    "    ##==========================================================================\n",
    "    if (args.cond_time=='prestim'):\n",
    "        subset= subset.crop(tmin=-0.4, tmax=0.05)\n",
    "    if (args.cond_time=='poststim'):\n",
    "        subset= subset.crop(tmin=0.05, tmax=0.45)\n",
    "    print('Shape of data is\\n :')\n",
    "    print(subset._data.shape)\n",
    "    ##==========================================================================\n",
    "    # Group data based on the previous trial\n",
    "    Grp1 = subset['Trgt_Loc_prev==1'].copy()\n",
    "    Grp2 = subset['Trgt_Loc_prev==2'].copy()\n",
    "    Grp3 = subset['Trgt_Loc_prev==3'].copy()\n",
    "    Grp4 = subset['Trgt_Loc_prev==4'].copy()\n",
    "    if main_ptrn==1:\n",
    "        Grp1 = Grp1['Trgt_Loc_main!=4'].copy()\n",
    "        Grp2 = Grp2['Trgt_Loc_main!=1'].copy()\n",
    "        Grp3 = Grp3['Trgt_Loc_main!=2'].copy()\n",
    "        Grp4 = Grp4['Trgt_Loc_main!=3'].copy()\n",
    "    ##==========================================================================\n",
    "    frequencies = np.arange(3, 13, 2)\n",
    "    if args.cond_decoding=='non_symm':\n",
    "        Grp1 = apply_nonSymm_filter(Grp1, frequencies)\n",
    "        Grp2 = apply_nonSymm_filter(Grp2, frequencies)\n",
    "        Grp3 = apply_nonSymm_filter(Grp3, frequencies)\n",
    "        Grp4 = apply_nonSymm_filter(Grp4, frequencies)\n",
    "    ##==========================================================================\n",
    "    print('the pattern for this subj is :=====================================')\n",
    "    print(main_ptrn)\n",
    "    print('          ')\n",
    "    print('===================================================================')\n",
    "    ##==========================================================================\n",
    "    # Normalizing the data for each subject\n",
    "    if args.normalization_type=='normal':\n",
    "        Grp1._data = (Grp1._data - np.mean(Grp1._data)) / np.std(Grp1._data)\n",
    "        Grp2._data = (Grp2._data - np.mean(Grp2._data)) / np.std(Grp2._data)\n",
    "        Grp3._data = (Grp3._data - np.mean(Grp3._data)) / np.std(Grp3._data)\n",
    "        Grp4._data = (Grp4._data - np.mean(Grp4._data)) / np.std(Grp4._data)\n",
    "    elif args.normalization_type=='lstmPaper':\n",
    "        Grp1._data = (2 * (Grp1._data - np.min(Grp1._data))) \\\n",
    "                        / (np.max(Grp1._data) - np.min(Grp1._data) - 1)\n",
    "        Grp2._data = (2 * (Grp2._data - np.min(Grp2._data))) \\\n",
    "                        / (np.max(Grp2._data) - np.min(Grp2._data) - 1)\n",
    "        Grp3._data = (2 * (Grp3._data - np.min(Grp3._data))) \\\n",
    "                        / (np.max(Grp3._data) - np.min(Grp3._data) - 1)\n",
    "        Grp4._data = (2 * (Grp4._data - np.min(Grp4._data))) \\\n",
    "                        / (np.max(Grp4._data) - np.min(Grp4._data) - 1)\n",
    "    ##==========================================================================\n",
    "    return Grp1, Grp2, Grp3, Grp4, main_ptrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, window, mode):\n",
    "    box = np.ones(window)/window\n",
    "    y_smooth = np.convolve(y, box, mode=mode)\n",
    "    return y_smooth\n",
    "\n",
    "def plot_scores(scores):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.tight_layout()\n",
    "    im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "                   extent=subset.times[[0, -1, 0 , -1]], vmin=0., vmax=0.6)\n",
    "    ax.set_xlabel('Testing Time (s)')\n",
    "    ax.set_ylabel('Training Time (s)')\n",
    "    ax.set_title('Temporal generalization')\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scores_diag(scores_diag, apply_smooth):\n",
    "    if apply_smooth:\n",
    "        window=50\n",
    "        mode='valid'\n",
    "        scores_diag = smooth(y, window, mode)\n",
    "        print(subset.times.shape)\n",
    "        print(y_smooth.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(subset.times, scores_diag, label='score')\n",
    "    ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "    ax.set_xlabel('Times')\n",
    "    ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "    ax.legend()\n",
    "    ax.axvline(.0, color='k', linestyle='-')\n",
    "    ax.set_title('Sensor space decoding')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_time_bin(data, indx, sbt):\n",
    "#     if sbt==0:\n",
    "#         avgs=np.zeros(len(indx))\n",
    "#         bs=np.array(np.split(data, indx))\n",
    "#         for ii in range(len(indx)):\n",
    "#             avgs[ii]=bs[ii].mean()\n",
    "#     if sbt==1:\n",
    "#          avgs=np.zeros([data.shape[0],len(indx)])\n",
    "#          aa=np.zeros(len(indx))\n",
    "#          for jj in range(data.shape[0]):\n",
    "#              bs=np.array(np.split(data[jj,:], indx))\n",
    "#              for ii in range(len(indx)):\n",
    "#                  aa[ii]=bs[ii].mean()\n",
    "#              avgs[jj,:]=aa\n",
    "#     if sbt==2:\n",
    "#          avgs=np.zeros([len(indx),len(indx)])\n",
    "#          aa=np.zeros(len(indx))\n",
    "#          for jj in range(data.shape[0]):\n",
    "#              bs1=np.array(np.split(data[jj,:], indx))\n",
    "#              bs2=np.array(np.split(data[:,jj], indx))\n",
    "#              for ii in range(len(indx)):\n",
    "#                  avgs[ii,:]=bs1[ii].mean()\n",
    "#                  avgs[:,ii]=bs2[ii].mean()\n",
    "\n",
    "#     return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_fonts():\n",
    "#     from matplotlib.font_manager import FontProperties\n",
    "#     font = FontProperties()\n",
    "#     font.set_family('serif')\n",
    "#     font.set_name('Calibri')\n",
    "#     return font\n",
    "\n",
    "# def plot_scores_stat(diag_scores, clusts):\n",
    "#     font=set_fonts();\n",
    "#     [t_obs, clusters, clusters_pv, H0] = clusts\n",
    "#     # binned times\n",
    "#     indx=[26,51,76,101,126,151,176,201,226,251]\n",
    "    \n",
    "# #     times=np.asarray([-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4])\n",
    "#     times=np.asarray([-0.4,-0.35,-0.3,-0.25,-0.2,-0.15,-0.1,0,0.05,0.15,0.2,0.25,0.3,0.35,0.4,0.45])\n",
    "#     extent_times=subset.times[[0, -1, 0, -1]]\n",
    "#     print(extent_times.shape)#4\n",
    "#     print(times.shape)#16\n",
    "#     print(diag_scores.shape)#10\n",
    "#     # Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     plt.tight_layout()\n",
    "#     ax.plot(times, diag_scores, label='score')\n",
    "#     ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "#     plt.ylim([0.43,0.65])\n",
    "#     ax.axvline(.0, color='k', linestyle='-')\n",
    "\n",
    "#     for i_clu, clu_idx in enumerate(clusters):\n",
    "#         clu_idx=clu_idx[0]\n",
    "#         print(clu_idx)\n",
    "#         # unpack cluster information, get unique indices\n",
    "#         if clusters_pv[i_clu] <= 0.05:\n",
    "#             h = plt.axvspan(times[clu_idx[0]], times[clu_idx[-1] - 1],\n",
    "#                             color='r', alpha=0.3)\n",
    "#             plt.legend((h, ), ('cluster p-value < 0.05', ))\n",
    "#         else:\n",
    "#             plt.axvspan(times[clu_idx[0]], times[clu_idx[-1] - 1], color=(0.3, 0.3, 0.3),\n",
    "#                         alpha=0.3)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.xlabel('Times',  fontproperties=font, fontsize=12, fontweight='bold')\n",
    "#     plt.ylabel('AUC', fontproperties=font, fontsize=12, fontweight='bold')#, labelpad=16,)\n",
    "#     plt.title('Decoding over time', fontproperties=font, fontweight='bold', fontsize=16)\n",
    "\n",
    "#     plt.legend(fontsize=11)\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stat_anal(scores_pck):\n",
    "# #     indx=[26,51,76,101,126,151,176,201]\n",
    "#     indx=[26,51,76,101,126,151,176,201,226,251]\n",
    "#     score, score_diag = scores_pck\n",
    "#     score_subtract = score_diag - 0.5\n",
    "    \n",
    "#     binned_score = do_time_bin(score, indx, 2)\n",
    "#     binned_score_diag = do_time_bin(score_diag, indx, 0)\n",
    "#     binned_score_subtract = do_time_bin(score_subtract, indx, 0)\n",
    "    \n",
    "#     print(score_subtract.shape)\n",
    "# #     score_subtract=score_subtract[:, np.newaxis, np.newaxis] # [:,:, np.newaxis] when added more subjects\n",
    "#     score_subtract=score_subtract[:, np.newaxis] # [:,:, np.newaxis] when added more subjects\n",
    "    \n",
    "#     print(score_subtract.shape)\n",
    "#     t_obs, clusters, clusters_pv, H0 = mne.stats.spatio_temporal_cluster_1samp_test(score_subtract, tail=0)\n",
    "    \n",
    "#     clust_pck = [t_obs, clusters, clusters_pv, H0]\n",
    "    \n",
    "#     return binned_score_diag, clust_pck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load nested list results using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_subj_P1 = [1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 15, 16, \\\n",
    "#                     42, 43, 44, 45, 47, 48, 51, 52, 53, \\\n",
    "#                     55, 56, 57, 58, 59, 60, 61, 62, 63, 64, \\\n",
    "#                     66, 67, 68, 69, 71, 72, 73, 74]\n",
    "# selected_subj_P2 = [18, 19, 20, 21, 23, 24, 26, 28, 29, 30, \\\n",
    "#                    31, 32, 33, 34, 35, 36, 38, 39]\n",
    "\n",
    "selected_subj_P1_E = [1, 8, 9, 16, 43, 45, 46, 48, 59, 60, 63, \\\n",
    "                      66, 68] # Early\n",
    "selected_subj_P1_L = [4, 8, 10, 15, 17, 43, 44, 45, 48, 52, 59, \\\n",
    "                      63, 64] # Later\n",
    "selected_subj_P1_B = [8, 43, 45, 48, 59, 63] # Both Early and Later\n",
    "\n",
    "\n",
    "\n",
    "selected_subj_P2_E = [26, 28, 35, 38, 39]\n",
    "selected_subj_P2_L = [20, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subj_scores(args, subj_p1, subj_p2):\n",
    "    avgp1_sc=[]\n",
    "    avgp2_sc=[]\n",
    "    avgp1_diag=[]\n",
    "    avgp2_diag=[]\n",
    "\n",
    "    avgp1_sc_fit=[]\n",
    "    avgp2_sc_fit=[]\n",
    "    avgp1_diag_fit=[]\n",
    "    avgp2_diag_fit=[]\n",
    "\n",
    "    for subj_id in subj_p1:\n",
    "        main_ptrn = 1\n",
    "        args.subj_num = subj_id\n",
    "\n",
    "        fn_str_sbj='scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s_Trgt_Loc_prev_Subj_%s' \\\n",
    "                %(args.cond_block, args.cond_filter, \\\n",
    "                  args.cond_decoding, args.applyBaseline_bool, \\\n",
    "                  args.n_splits, args.subj_num)\n",
    "\n",
    "        fn_str = args.SAVE_RESULT_ROOT + 'rand_avgP%s_' %(main_ptrn) + fn_str_sbj\n",
    "\n",
    "\n",
    "        with open(fn_str, 'rb') as f:\n",
    "            sc_subj_pck = pickle.load(f)\n",
    "\n",
    "        avgp1_sc.append(sc_subj_pck[0])\n",
    "        avgp1_diag.append(sc_subj_pck[1])\n",
    "\n",
    "        avgp1_sc_fit.append(sc_subj_pck[2])\n",
    "        avgp1_diag_fit.append(sc_subj_pck[3])\n",
    "\n",
    "    for subj_id in subj_p2:\n",
    "        main_ptrn = 2\n",
    "        args.subj_num = subj_id\n",
    "\n",
    "        fn_str_sbj='scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s_Trgt_Loc_prev_Subj_%s' \\\n",
    "                %(args.cond_block, args.cond_filter, \\\n",
    "                  args.cond_decoding, args.applyBaseline_bool, \\\n",
    "                  args.n_splits, args.subj_num)\n",
    "\n",
    "        fn_str = args.SAVE_RESULT_ROOT + 'rand_avgP%s_' %(main_ptrn) + fn_str_sbj\n",
    "\n",
    "\n",
    "        with open(fn_str, 'rb') as f:\n",
    "            sc_subj_pck = pickle.load(f)\n",
    "\n",
    "\n",
    "        avgp2_sc.append(sc_subj_pck[0])\n",
    "        avgp2_diag.append(sc_subj_pck[1])\n",
    "\n",
    "        avgp2_sc_fit.append(sc_subj_pck[2])\n",
    "        avgp2_diag_fit.append(sc_subj_pck[3])\n",
    "\n",
    "\n",
    "    print(np.asarray(avgp1_diag).shape)\n",
    "    print(np.asarray(avgp2_diag).shape)\n",
    "\n",
    "    p1=np.asarray(avgp1_sc)\n",
    "    p2=np.asarray(avgp2_sc)\n",
    "    p=np.concatenate((p1, p2), axis=0)\n",
    "\n",
    "    p1d=np.asarray(avgp1_diag)\n",
    "    p2d=np.asarray(avgp2_diag)\n",
    "    pd=np.concatenate((p1d, p2d), axis=0)\n",
    "\n",
    "    scores_pck_p = [p, pd]\n",
    "    \n",
    "    return scores_pck_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/temp_gen/blanca/\n",
      "(13, 100, 213)\n",
      "(5, 100, 213)\n"
     ]
    }
   ],
   "source": [
    "# early ------------- #\n",
    "# cond_block, cond_decoding, applyBaseline_bool, mtdt_feat, occ_channels)\n",
    "args = arguments('early', 'removeevoked', 'False', 'Trgt_Loc_main', 'False' )\n",
    "scores_pck_p_e = combine_subj_scores(args, selected_subj_P1_E, selected_subj_P2_E)\n",
    "avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "\n",
    "\n",
    "# late ------------- #\n",
    "# args = arguments('later', 'removeevoked', 'False', 'Trgt_Loc_main', 'False' )\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1_L, selected_subj_P2_L)\n",
    "# print('p later all subjects:',scores_pck_p_l.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 100, 213, 213)\n",
      "(18, 100, 213)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-455116735abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgP_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_scores_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgPdiag_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-59f196754529>\u001b[0m in \u001b[0;36mplot_scores\u001b[0;34m(scores)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n\u001b[0;32m---> 10\u001b[0;31m                    extent=subset.times[[0, -1, 0 , -1]], vmin=0., vmax=0.6)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing Time (s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Time (s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subset' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(res_e[0].shape)\n",
    "print(res_e[1].shape)\n",
    "\n",
    "plot_scores(avgP_e)\n",
    "plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'False', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond2\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'True', '_100k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'True', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond3\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond4\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'True', '_3k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'none', 'False', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'none', 'False', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'none', 'True', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'none', 'True', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
