{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if saving and everything else has been correctly done after run the script for prestim later none filter on eCortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import cross_val_multiscore, LinearModel, GeneralizingEstimator, Scaler, \\\n",
    "                         Vectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, StratifiedShuffleSplit, \\\n",
    "                                    RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import argparse\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments:\n",
    "    def __init__(self, cond_block, cond_decoding, applyBaseline_bool, mtdt_feat, occ_channels):\n",
    "        self.cond_block = cond_block #'later' #{early,later}\n",
    "        self.cond_decoding = cond_decoding #'removeevoked' #{none,removeevoked,resampled}\n",
    "        self.applyBaseline_bool = applyBaseline_bool #'False'\n",
    "        self.mtdt_feat = mtdt_feat\n",
    "        self.occ_channels = occ_channels\n",
    "        \n",
    "        self.SAVE_EPOCH_ROOT = '../../../data/version5.2/preprocessed/epochs/aft_ICA_rej'\n",
    "        self.SAVE_RESULT_ROOT = '../../../results/temp_gen/temp_gen/blanca/'\n",
    "        self.cond_filter ='none' # {none,non_symm}\n",
    "        self.cond_time = 'prestim' #{prestim,poststim}\n",
    "        self.subj_num = 1\n",
    "        self.pre_tmin = -0.4\n",
    "        self.pre_tmax = 0.05\n",
    "        self.post_tmin = 0.05\n",
    "        self.post_tmax = 0.45\n",
    "        self.num_classes = 2\n",
    "        self.normalization_type = 'normal'# {normal,lstmPaper}\n",
    "        self.gen_rand_perm = 0\n",
    "        self.null_max_iter = 10000\n",
    "        self.loop_null_iter = 5\n",
    "        self.gen_decoder_scores = 1\n",
    "        self.random_state = 42 \n",
    "        self.max_iter = 10000\n",
    "        self.n_jobs = 1\n",
    "        self.scoring = 'roc_auc'\n",
    "        self.n_splits = '_3k'\n",
    "        print(self.SAVE_RESULT_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class arguments:\n",
    "#     def __init__(self, cond_block, cond_decoding, applyBaseline_bool, n_splits):\n",
    "#         self.cond_block = cond_block #'later' #{early,later}\n",
    "#         self.cond_decoding = cond_decoding #'removeevoked' #{none,removeevoked,resampled}\n",
    "#         self.applyBaseline_bool = applyBaseline_bool #'False'\n",
    "#         self.n_splits = n_splits#100\n",
    "\n",
    "#         self.SAVE_EPOCH_ROOT = '../../data/version5.2/preprocessed/epochs/aft_ICA_rej/'\n",
    "#         self.SAVE_RESULT_ROOT = '../../results/temp_gen/eCortex/'\n",
    "#         self.cond_filter ='none' # {none,non_symm}\n",
    "#         self.cond_time = 'prestim' #{prestim,poststim}\n",
    "#         self.subj_num = 1\n",
    "#         self.pre_tmin = -0.4\n",
    "#         self.pre_tmax = 0.05\n",
    "#         self.post_tmin = 0.05\n",
    "#         self.post_tmax = 0.45\n",
    "#         self.num_classes = 2\n",
    "#         self.normalization_type = 'normal'# {normal,lstmPaper}\n",
    "#         self.gen_rand_perm = 0\n",
    "#         self.null_max_iter = 10000\n",
    "#         self.loop_null_iter = 5\n",
    "#         self.gen_decoder_scores = 1\n",
    "#         self.random_state = 42 \n",
    "#         self.max_iter = 10000\n",
    "#         self.n_jobs = 1\n",
    "#         self.scoring = 'roc_auc'\n",
    "#         self.folder='noneFilter_PrePost_decod%s_bsline%s%s/' %(cond_decoding, \\\n",
    "#                                                        applyBaseline_bool, \\\n",
    "#                                                        n_splits)\n",
    "#         self.SAVE_RESULT_ROOT = self.SAVE_RESULT_ROOT + self.folder\n",
    "#         print(self.SAVE_RESULT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading and preparing epoch data to create each 4 grous and 2 pattern\n",
    "\"\"\"\n",
    "def read_prep_epochs(args):\n",
    "    if args.applyBaseline_bool:\n",
    "        filename_epoch = args.SAVE_EPOCH_ROOT + \\\n",
    "                         'epochs_sec_applyBaseline_subj%s-afterRejICA-epo.fif' \\\n",
    "                          %args.subj_num\n",
    "    else:\n",
    "        filename_epoch = args.SAVE_EPOCH_ROOT + \\\n",
    "                         'epochs_sec_subj%s-afterRejICA-epo.fif' \\\n",
    "                         %args.subj_num\n",
    "    epochs_orig = mne.read_epochs(filename_epoch, proj=True, preload=True,\n",
    "                                  verbose=None)\n",
    "    epochs = epochs_orig.copy()\n",
    "    subset = epochs['pred']['non'].copy()\n",
    "    subset = subset.pick_types(eeg=True)\n",
    "    if (args.cond_decoding=='removeevoked'):\n",
    "        # REMOVE EVOKED RESP.\n",
    "        subset.subtract_evoked()    # remove evoked response\n",
    "    elif (args.cond_decoding=='resampled'):\n",
    "        # RESAMPLE\n",
    "        subset = subset.resample(args.n_resampling, npad='auto')\n",
    "    else:\n",
    "        pass\n",
    "    ##==========================================================================\n",
    "    if subset['Block==7'].metadata.Ptrn_Type.values.shape[0]>0:\n",
    "       main_ptrn = subset['Block==7'].metadata.Ptrn_Type.values[0]\n",
    "    else:\n",
    "       main_ptrn = subset['Block==8'].metadata.Ptrn_Type.values[0]\n",
    "    ##==========================================================================\n",
    "    if args.cond_block=='early': #block 3-6\n",
    "        subset = subset['Block<7'].copy()\n",
    "        subset = subset['Block>2'].copy()\n",
    "    elif args.cond_block=='later':#block 7-10\n",
    "        subset = subset['Block<11'].copy()\n",
    "        subset = subset['Block>6'].copy()\n",
    "    ##==========================================================================\n",
    "    if (args.cond_time=='prestim'):\n",
    "        subset= subset.crop(tmin=-0.4, tmax=0.05)\n",
    "    if (args.cond_time=='poststim'):\n",
    "        subset= subset.crop(tmin=0.05, tmax=0.45)\n",
    "    print('Shape of data is\\n :')\n",
    "    print(subset._data.shape)\n",
    "    ##==========================================================================\n",
    "    # Group data based on the previous trial\n",
    "    Grp1 = subset['Trgt_Loc_prev==1'].copy()\n",
    "    Grp2 = subset['Trgt_Loc_prev==2'].copy()\n",
    "    Grp3 = subset['Trgt_Loc_prev==3'].copy()\n",
    "    Grp4 = subset['Trgt_Loc_prev==4'].copy()\n",
    "    if main_ptrn==1:\n",
    "        Grp1 = Grp1['Trgt_Loc_main!=4'].copy()\n",
    "        Grp2 = Grp2['Trgt_Loc_main!=1'].copy()\n",
    "        Grp3 = Grp3['Trgt_Loc_main!=2'].copy()\n",
    "        Grp4 = Grp4['Trgt_Loc_main!=3'].copy()\n",
    "    ##==========================================================================\n",
    "    frequencies = np.arange(3, 13, 2)\n",
    "    if args.cond_decoding=='non_symm':\n",
    "        Grp1 = apply_nonSymm_filter(Grp1, frequencies)\n",
    "        Grp2 = apply_nonSymm_filter(Grp2, frequencies)\n",
    "        Grp3 = apply_nonSymm_filter(Grp3, frequencies)\n",
    "        Grp4 = apply_nonSymm_filter(Grp4, frequencies)\n",
    "    ##==========================================================================\n",
    "    print('the pattern for this subj is :=====================================')\n",
    "    print(main_ptrn)\n",
    "    print('          ')\n",
    "    print('===================================================================')\n",
    "    ##==========================================================================\n",
    "    # Normalizing the data for each subject\n",
    "    if args.normalization_type=='normal':\n",
    "        Grp1._data = (Grp1._data - np.mean(Grp1._data)) / np.std(Grp1._data)\n",
    "        Grp2._data = (Grp2._data - np.mean(Grp2._data)) / np.std(Grp2._data)\n",
    "        Grp3._data = (Grp3._data - np.mean(Grp3._data)) / np.std(Grp3._data)\n",
    "        Grp4._data = (Grp4._data - np.mean(Grp4._data)) / np.std(Grp4._data)\n",
    "    elif args.normalization_type=='lstmPaper':\n",
    "        Grp1._data = (2 * (Grp1._data - np.min(Grp1._data))) \\\n",
    "                        / (np.max(Grp1._data) - np.min(Grp1._data) - 1)\n",
    "        Grp2._data = (2 * (Grp2._data - np.min(Grp2._data))) \\\n",
    "                        / (np.max(Grp2._data) - np.min(Grp2._data) - 1)\n",
    "        Grp3._data = (2 * (Grp3._data - np.min(Grp3._data))) \\\n",
    "                        / (np.max(Grp3._data) - np.min(Grp3._data) - 1)\n",
    "        Grp4._data = (2 * (Grp4._data - np.min(Grp4._data))) \\\n",
    "                        / (np.max(Grp4._data) - np.min(Grp4._data) - 1)\n",
    "    ##==========================================================================\n",
    "    return Grp1, Grp2, Grp3, Grp4, main_ptrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, window, mode):\n",
    "    box = np.ones(window)/window\n",
    "    y_smooth = np.convolve(y, box, mode=mode)\n",
    "    return y_smooth\n",
    "\n",
    "def plot_scores(scores):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.tight_layout()\n",
    "    im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "                   extent=subset.times[[0, -1, 0 , -1]], vmin=0., vmax=0.6)\n",
    "    ax.set_xlabel('Testing Time (s)')\n",
    "    ax.set_ylabel('Training Time (s)')\n",
    "    ax.set_title('Temporal generalization')\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scores_diag(scores_diag, apply_smooth):\n",
    "    if apply_smooth:\n",
    "        window=50\n",
    "        mode='valid'\n",
    "        scores_diag = smooth(y, window, mode)\n",
    "        print(subset.times.shape)\n",
    "        print(y_smooth.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(subset.times, scores_diag, label='score')\n",
    "    ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "    ax.set_xlabel('Times')\n",
    "    ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "    ax.legend()\n",
    "    ax.axvline(.0, color='k', linestyle='-')\n",
    "    ax.set_title('Sensor space decoding')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "60\n",
      "90\n",
      "asdfasdf\n",
      "\n",
      "\n",
      "sdsd\n"
     ]
    }
   ],
   "source": [
    "for nitr in range(100):\n",
    "    if (nitr>0 and nitr%30==0):\n",
    "        print(nitr)\n",
    "print('asdfasdf')\n",
    "print('\\n')\n",
    "print('sdsd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_time_bin(data, indx, sbt):\n",
    "#     if sbt==0:\n",
    "#         avgs=np.zeros(len(indx))\n",
    "#         bs=np.array(np.split(data, indx))\n",
    "#         for ii in range(len(indx)):\n",
    "#             avgs[ii]=bs[ii].mean()\n",
    "#     if sbt==1:\n",
    "#          avgs=np.zeros([data.shape[0],len(indx)])\n",
    "#          aa=np.zeros(len(indx))\n",
    "#          for jj in range(data.shape[0]):\n",
    "#              bs=np.array(np.split(data[jj,:], indx))\n",
    "#              for ii in range(len(indx)):\n",
    "#                  aa[ii]=bs[ii].mean()\n",
    "#              avgs[jj,:]=aa\n",
    "#     if sbt==2:\n",
    "#          avgs=np.zeros([len(indx),len(indx)])\n",
    "#          aa=np.zeros(len(indx))\n",
    "#          for jj in range(data.shape[0]):\n",
    "#              bs1=np.array(np.split(data[jj,:], indx))\n",
    "#              bs2=np.array(np.split(data[:,jj], indx))\n",
    "#              for ii in range(len(indx)):\n",
    "#                  avgs[ii,:]=bs1[ii].mean()\n",
    "#                  avgs[:,ii]=bs2[ii].mean()\n",
    "\n",
    "#     return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_fonts():\n",
    "#     from matplotlib.font_manager import FontProperties\n",
    "#     font = FontProperties()\n",
    "#     font.set_family('serif')\n",
    "#     font.set_name('Calibri')\n",
    "#     return font\n",
    "\n",
    "# def plot_scores_stat(diag_scores, clusts):\n",
    "#     font=set_fonts();\n",
    "#     [t_obs, clusters, clusters_pv, H0] = clusts\n",
    "#     # binned times\n",
    "#     indx=[26,51,76,101,126,151,176,201,226,251]\n",
    "    \n",
    "# #     times=np.asarray([-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4])\n",
    "#     times=np.asarray([-0.4,-0.35,-0.3,-0.25,-0.2,-0.15,-0.1,0,0.05,0.15,0.2,0.25,0.3,0.35,0.4,0.45])\n",
    "#     extent_times=subset.times[[0, -1, 0, -1]]\n",
    "#     print(extent_times.shape)#4\n",
    "#     print(times.shape)#16\n",
    "#     print(diag_scores.shape)#10\n",
    "#     # Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     plt.tight_layout()\n",
    "#     ax.plot(times, diag_scores, label='score')\n",
    "#     ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "#     plt.ylim([0.43,0.65])\n",
    "#     ax.axvline(.0, color='k', linestyle='-')\n",
    "\n",
    "#     for i_clu, clu_idx in enumerate(clusters):\n",
    "#         clu_idx=clu_idx[0]\n",
    "#         print(clu_idx)\n",
    "#         # unpack cluster information, get unique indices\n",
    "#         if clusters_pv[i_clu] <= 0.05:\n",
    "#             h = plt.axvspan(times[clu_idx[0]], times[clu_idx[-1] - 1],\n",
    "#                             color='r', alpha=0.3)\n",
    "#             plt.legend((h, ), ('cluster p-value < 0.05', ))\n",
    "#         else:\n",
    "#             plt.axvspan(times[clu_idx[0]], times[clu_idx[-1] - 1], color=(0.3, 0.3, 0.3),\n",
    "#                         alpha=0.3)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.xlabel('Times',  fontproperties=font, fontsize=12, fontweight='bold')\n",
    "#     plt.ylabel('AUC', fontproperties=font, fontsize=12, fontweight='bold')#, labelpad=16,)\n",
    "#     plt.title('Decoding over time', fontproperties=font, fontweight='bold', fontsize=16)\n",
    "\n",
    "#     plt.legend(fontsize=11)\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stat_anal(scores_pck):\n",
    "# #     indx=[26,51,76,101,126,151,176,201]\n",
    "#     indx=[26,51,76,101,126,151,176,201,226,251]\n",
    "#     score, score_diag = scores_pck\n",
    "#     score_subtract = score_diag - 0.5\n",
    "    \n",
    "#     binned_score = do_time_bin(score, indx, 2)\n",
    "#     binned_score_diag = do_time_bin(score_diag, indx, 0)\n",
    "#     binned_score_subtract = do_time_bin(score_subtract, indx, 0)\n",
    "    \n",
    "#     print(score_subtract.shape)\n",
    "# #     score_subtract=score_subtract[:, np.newaxis, np.newaxis] # [:,:, np.newaxis] when added more subjects\n",
    "#     score_subtract=score_subtract[:, np.newaxis] # [:,:, np.newaxis] when added more subjects\n",
    "    \n",
    "#     print(score_subtract.shape)\n",
    "#     t_obs, clusters, clusters_pv, H0 = mne.stats.spatio_temporal_cluster_1samp_test(score_subtract, tail=0)\n",
    "    \n",
    "#     clust_pck = [t_obs, clusters, clusters_pv, H0]\n",
    "    \n",
    "#     return binned_score_diag, clust_pck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load nested list results using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_subj_P1 = [1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 15, 16, \\\n",
    "#                     42, 43, 44, 45, 47, 48, 51, 52, 53, \\\n",
    "#                     55, 56, 57, 58, 59, 60, 61, 62, 63, 64, \\\n",
    "#                     66, 67, 68, 69, 71, 72, 73, 74]\n",
    "# selected_subj_P2 = [18, 19, 20, 21, 23, 24, 26, 28, 29, 30, \\\n",
    "#                    31, 32, 33, 34, 35, 36, 38, 39]\n",
    "\n",
    "selected_subj_P1_E = [1, 8, 9, 16, 43, 45, 46, 48, 59, 60, 63, \\\n",
    "                      66, 68] # Early\n",
    "selected_subj_P1_L = [4, 8, 10, 15, 17, 43, 44, 45, 48, 52, 59, \\\n",
    "                      63, 64] # Later\n",
    "selected_subj_P1_B = [8, 43, 45, 48, 59, 63] # Both Early and Later\n",
    "\n",
    "\n",
    "\n",
    "selected_subj_P2_E = [26, 28, 35, 38, 39]\n",
    "selected_subj_P2_L = [20, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subj_scores(args, subj_p1, subj_p2):\n",
    "    avgp1_sc=[]\n",
    "    avgp2_sc=[]\n",
    "    avgp1_diag=[]\n",
    "    avgp2_diag=[]\n",
    "\n",
    "    avgp1_sc_fit=[]\n",
    "    avgp2_sc_fit=[]\n",
    "    avgp1_diag_fit=[]\n",
    "    avgp2_diag_fit=[]\n",
    "\n",
    "    for subj_id in subj_p1:\n",
    "        main_ptrn = 1\n",
    "        args.subj_num = subj_id\n",
    "\n",
    "        fn_str_sbj='scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s_Trgt_Loc_prev_Subj_%s' \\\n",
    "                %(args.cond_block, args.cond_filter, \\\n",
    "                  args.cond_decoding, args.applyBaseline_bool, \\\n",
    "                  args.n_splits, args.subj_num)\n",
    "\n",
    "        fn_str = args.SAVE_RESULT_ROOT + 'rand_avgP%s_' %(main_ptrn) + fn_str_sbj\n",
    "\n",
    "\n",
    "        with open(fn_str, 'rb') as f:\n",
    "            sc_subj_pck = pickle.load(f)\n",
    "\n",
    "        avgp1_sc.append(sc_subj_pck[0])\n",
    "        avgp1_diag.append(sc_subj_pck[1])\n",
    "\n",
    "        avgp1_sc_fit.append(sc_subj_pck[2])\n",
    "        avgp1_diag_fit.append(sc_subj_pck[3])\n",
    "\n",
    "    for subj_id in subj_p2:\n",
    "        main_ptrn = 2\n",
    "        args.subj_num = subj_id\n",
    "\n",
    "        fn_str_sbj='scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s_Trgt_Loc_prev_Subj_%s' \\\n",
    "                %(args.cond_block, args.cond_filter, \\\n",
    "                  args.cond_decoding, args.applyBaseline_bool, \\\n",
    "                  args.n_splits, args.subj_num)\n",
    "\n",
    "        fn_str = args.SAVE_RESULT_ROOT + 'rand_avgP%s_' %(main_ptrn) + fn_str_sbj\n",
    "\n",
    "\n",
    "        with open(fn_str, 'rb') as f:\n",
    "            sc_subj_pck = pickle.load(f)\n",
    "\n",
    "\n",
    "        avgp2_sc.append(sc_subj_pck[0])\n",
    "        avgp2_diag.append(sc_subj_pck[1])\n",
    "\n",
    "        avgp2_sc_fit.append(sc_subj_pck[2])\n",
    "        avgp2_diag_fit.append(sc_subj_pck[3])\n",
    "\n",
    "\n",
    "    print(np.asarray(avgp1_diag).shape)\n",
    "    print(np.asarray(avgp2_diag).shape)\n",
    "\n",
    "    p1=np.asarray(avgp1_sc)\n",
    "    p2=np.asarray(avgp2_sc)\n",
    "    p=np.concatenate((p1, p2), axis=0)\n",
    "\n",
    "    p1d=np.asarray(avgp1_diag)\n",
    "    p2d=np.asarray(avgp2_diag)\n",
    "    pd=np.concatenate((p1d, p2d), axis=0)\n",
    "\n",
    "    scores_pck_p = [p, pd]\n",
    "    \n",
    "    return scores_pck_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/temp_gen/temp_gen/blanca/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../results/temp_gen/temp_gen/blanca/rand_avgP1_scores_timeGen_earlyBlocks_noneFilter_PrePost_decodremoveevoked_bslineFalse_3k_Trgt_Loc_prev_Subj_43'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a5622349cd9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# cond_block, cond_decoding, applyBaseline_bool, mtdt_feat, occ_channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'early'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removeevoked'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trgt_Loc_main'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'False'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscores_pck_p_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_subj_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_subj_P1_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_subj_P2_E\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mavgP_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_pck_p_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mavgPdiag_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_pck_p_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-0fa557c74ef9>\u001b[0m in \u001b[0;36mcombine_subj_scores\u001b[0;34m(args, subj_p1, subj_p2)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0msc_subj_pck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../results/temp_gen/temp_gen/blanca/rand_avgP1_scores_timeGen_earlyBlocks_noneFilter_PrePost_decodremoveevoked_bslineFalse_3k_Trgt_Loc_prev_Subj_43'"
     ]
    }
   ],
   "source": [
    "# early ------------- #\n",
    "# cond_block, cond_decoding, applyBaseline_bool, mtdt_feat, occ_channels)\n",
    "args = arguments('early', 'removeevoked', 'False', 'Trgt_Loc_main', 'False' )\n",
    "scores_pck_p_e = combine_subj_scores(args, selected_subj_P1_E, selected_subj_P2_E)\n",
    "avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "\n",
    "\n",
    "# late ------------- #\n",
    "# args = arguments('later', 'removeevoked', 'False', 'Trgt_Loc_main', 'False' )\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1_L, selected_subj_P2_L)\n",
    "# print('p later all subjects:',scores_pck_p_l.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-455116735abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_e\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgP_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_scores_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgPdiag_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res_e' is not defined"
     ]
    }
   ],
   "source": [
    "print(res_e[0].shape)\n",
    "print(res_e[1].shape)\n",
    "\n",
    "plot_scores(avgP_e)\n",
    "plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'False', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond2\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'True', '_100k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'True', '_100k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond3\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond4\n",
    "Not complete yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'removeevoked', 'True', '_3k' )\n",
    "# # ------------- #\n",
    "# # scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# # avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# # avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # # ------------- #\n",
    "# # conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "# #                 %(args.cond_block, args.cond_filter, \\\n",
    "# #                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "# #                 args.n_splits)\n",
    "# # # ------------- #\n",
    "# # print(conds)\n",
    "# # # ------------- #\n",
    "# # plot_scores(avgP_e)\n",
    "# # plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'removeevoked', 'False', '_3k' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'none', 'False', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'none', 'False', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cond6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('early', 'none', 'True', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_e = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_e = np.mean(scores_pck_p_e[0], axis=0)\n",
    "# avgPdiag_e = np.mean(scores_pck_p_e[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_e)\n",
    "# plot_scores_diag(avgPdiag_e, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = arguments('later', 'none', 'True', '' )\n",
    "# # ------------- #\n",
    "# scores_pck_p_l = combine_subj_scores(args, selected_subj_P1, selected_subj_P2)\n",
    "# avgP_l = np.mean(scores_pck_p_l[0], axis=0)\n",
    "# avgPdiag_l = np.mean(scores_pck_p_l[1], axis=0)\n",
    "# # ------------- #\n",
    "# conds = 'scores_timeGen_%sBlocks_%sFilter_PrePost_decod%s_bsline%s%s' \\\n",
    "#                 %(args.cond_block, args.cond_filter, \\\n",
    "#                 args.cond_decoding, args.applyBaseline_bool, \\\n",
    "#                 args.n_splits)\n",
    "# # ------------- #\n",
    "# print(conds)\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_l)\n",
    "# plot_scores_diag(avgPdiag_l, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgP_diff = avgP_l - avgP_e\n",
    "# avgPdiag_diff = avgPdiag_l - avgPdiag_e\n",
    "# # ------------- #\n",
    "# plot_scores(avgP_diff)\n",
    "# plot_scores_diag(avgPdiag_diff, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
