{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import mne\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from mne.decoding import cross_val_multiscore, LinearModel, \\\n",
    "                         GeneralizingEstimator, Scaler, Vectorizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, StratifiedShuffleSplit, \\\n",
    "                                    RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments:\n",
    "    def __init__(self, cond_block, cond_decoding, applyBaseline_bool, n_splits):\n",
    "        self.cond_block = cond_block #'later' #{early,later}\n",
    "        self.cond_decoding = cond_decoding #'removeevoked' #{none,removeevoked,resampled}\n",
    "        self.applyBaseline_bool = applyBaseline_bool #'False'\n",
    "        self.n_splits = n_splits#100\n",
    "\n",
    "        self.SAVE_EPOCH_ROOT = '../../data/version5.2/preprocessed/epochs/aft_ICA_rej/'\n",
    "        self.SAVE_RESULT_ROOT = '../../results/autocorr/eCortex/'\n",
    "        self.cond_filter ='none' # {none,non_symm}\n",
    "        self.cond_time = 'prestim' #{prestim,poststim}\n",
    "        self.subj_num = 1\n",
    "        self.pre_tmin = -0.4\n",
    "        self.pre_tmax = 0.05\n",
    "        self.post_tmin = 0.05\n",
    "        self.post_tmax = 0.45\n",
    "        self.num_classes = 2\n",
    "        self.normalization_type = 'normal'# {normal,lstmPaper}\n",
    "        self.gen_rand_perm = 0\n",
    "        self.null_max_iter = 10000\n",
    "        self.loop_null_iter = 1\n",
    "        self.gen_decoder_scores = 1\n",
    "        self.random_state = 42 \n",
    "        self.max_iter = 10000\n",
    "        self.n_jobs = 1\n",
    "        self.scoring = 'roc_auc'\n",
    "        self.folder='noneFilter_PrePost_decod%s_bsline%s%s/' %(cond_decoding, \\\n",
    "                                                       applyBaseline_bool, \\\n",
    "                                                       n_splits)\n",
    "#         self.SAVE_RESULT_ROOT = self.SAVE_RESULT_ROOT + self.folder\n",
    "        print(self.SAVE_RESULT_ROOT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../data/version5.2/preprocessed/epochs/aft_ICA_rej/epochs_sec_applyBaseline_subj1-afterRejICA-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 129) active\n",
      "    Found the data of interest:\n",
      "        t =    -400.00 ...    5000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1197 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Adding metadata with 16 columns\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   876 events (all good), -0.4 - 0.5 sec, baseline [-0.4, 0], ~195.1 MB, data loaded, with metadata,\n",
       " 'pred/down/non': 216\n",
       " 'pred/left/non': 224\n",
       " 'pred/right/non': 219\n",
       " 'pred/up/non': 217>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE_EPOCH_ROOT = '../../data/preprocessed/epochs/aft_ICA_rej/'\n",
    "SAVE_EPOCH_ROOT = '../../data/version5.2/preprocessed/epochs/aft_ICA_rej/'\n",
    "filename_epoch = SAVE_EPOCH_ROOT +  'epochs_sec_applyBaseline_subj1-afterRejICA-epo.fif'\n",
    "\n",
    "#Read Epochs\n",
    "epochs_orig = mne.read_epochs(filename_epoch, proj=True, preload=True, verbose=None)\n",
    "epochs = epochs_orig.copy()\n",
    "subset = epochs['pred']['non'].copy()\n",
    "subset = subset.pick_types(eeg=True)\n",
    "subset.crop(tmin=-0.4,tmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset['Block==6'].metadata.Ptrn_Type.values.shape[0]>0:\n",
    "       main_ptrn = subset['Block==6'].metadata.Ptrn_Type.values[0]\n",
    "else:\n",
    "       main_ptrn = subset['Block==8'].metadata.Ptrn_Type.values[0]\n",
    "\n",
    "# only early blocks\n",
    "subset = subset['Block<7'].copy()\n",
    "subset = subset['Block>2'].copy()\n",
    "\n",
    "# Group data based on the previous trial\n",
    "Grp1 = subset['Trgt_Loc_prev==1'].copy()\n",
    "Grp2 = subset['Trgt_Loc_prev==2'].copy()\n",
    "Grp3 = subset['Trgt_Loc_prev==3'].copy()\n",
    "Grp4 = subset['Trgt_Loc_prev==4'].copy()\n",
    "\n",
    "Grp1._data = (Grp1._data - np.mean(Grp1._data)) / np.std(Grp1._data)\n",
    "Grp2._data = (Grp2._data - np.mean(Grp2._data)) / np.std(Grp2._data)\n",
    "Grp3._data = (Grp3._data - np.mean(Grp3._data)) / np.std(Grp3._data)\n",
    "Grp4._data = (Grp4._data - np.mean(Grp4._data)) / np.std(Grp4._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/autocorr/eCortex/\n"
     ]
    }
   ],
   "source": [
    "args = arguments('early', 'none', 'False', 3)\n",
    "cv = StratifiedShuffleSplit(n_splits=args.n_splits, \\\n",
    "                            random_state=args.random_state)\n",
    "Grp_data = Grp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************\n",
      "Start of the rand loop:\n",
      "\n",
      "2020-04-13 21:20:14.442753\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "Iteration:\n",
      "\n",
      "2020-04-13 21:20:14.443591\n",
      "0\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "Iteration:\n",
      "\n",
      "2020-04-13 21:31:50.523682\n",
      "1\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "Iteration:\n",
      "\n",
      "2020-04-13 21:43:10.059941\n",
      "2\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "Iteration:\n",
      "\n",
      "2020-04-13 21:54:37.586339\n",
      "3\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "Iteration:\n",
      "\n",
      "2020-04-13 22:06:06.951523\n",
      "4\n",
      "**************************************************************\n",
      "**************************************************************\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "[............................................................] 100.00% Fitting GeneralizingEstimator |\n",
      "[............................................................] 100.00% Scoring GeneralizingEstimator |\n",
      "**************************************************************\n",
      "End of the rand loop:\n",
      "\n",
      "2020-04-13 22:19:36.941245\n",
      "**************************************************************\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "clf_SVC  = make_pipeline(\n",
    "                      StandardScaler(),\n",
    "                      LinearModel(LinearSVC(random_state=args.random_state,\n",
    "                                            max_iter=args.null_max_iter)))\n",
    "\n",
    "X = Grp_data.copy()._data\n",
    "y = le.fit_transform(Grp_data.copy().metadata.Trgt_Loc_main)\n",
    "\n",
    "rand_scores = []\n",
    "rand_diag = []\n",
    "\n",
    "rand_scores_fit = []\n",
    "rand_diag_fit = []\n",
    "print('**************************************************************')\n",
    "print('Start of the rand loop:\\n')\n",
    "print(str(datetime.datetime.now()))\n",
    "print('**************************************************************')\n",
    "\n",
    "for nitr in range(args.loop_null_iter):\n",
    "    print('**************************************************************')\n",
    "    print('**************************************************************')\n",
    "    print('Iteration:\\n')\n",
    "    print(str(datetime.datetime.now()))\n",
    "    print(nitr)\n",
    "    print('**************************************************************')\n",
    "    print('**************************************************************')\n",
    "    true_Y = y.copy();\n",
    "    indx = np.random.permutation(true_Y.shape[0]);\n",
    "    shuffled_Y = true_Y.copy()[indx];\n",
    "    shuffled_Y = le.fit_transform(shuffled_Y.copy());\n",
    "\n",
    "    time_gen = GeneralizingEstimator(clf_SVC, scoring=args.scoring,\n",
    "                                     n_jobs=args.n_jobs, verbose=True)\n",
    "    # print(np.unique(y))\n",
    "    # print(np.unique(Grp_data.copy().metadata.Trgt_Loc_main))\n",
    "\n",
    "    scores = cross_val_multiscore(time_gen, X, shuffled_Y, cv=cv, n_jobs=args.n_jobs)\n",
    "    scores = np.mean(scores, axis=0) #scores with cv\n",
    "    scores_diag = np.diag(scores)\n",
    "\n",
    "    rand_scores.append(scores)\n",
    "    rand_diag.append(scores_diag)\n",
    "\n",
    "    # Without using cv, train and test on the same data\n",
    "    X = Grp_data.copy()._data\n",
    "    y = le.fit_transform(Grp_data.copy().metadata.Trgt_Loc_main)\n",
    "    time_gen.fit(X=X ,y=y)\n",
    "    scores = time_gen.score(X=X, y=y) #scores without cv\n",
    "    scores_diag = np.diag(scores)\n",
    "\n",
    "    rand_scores_fit.append(scores)\n",
    "    rand_diag_fit.append(scores_diag)\n",
    "print('**************************************************************')\n",
    "print('End of the rand loop:\\n')\n",
    "print(str(datetime.datetime.now()))\n",
    "print('**************************************************************')\n",
    "rand_scores_pck = (rand_scores.copy(), rand_diag.copy())\n",
    "rand_scores_pck_fit = (rand_scores_fit.copy(), rand_diag_fit.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_pck_G1 = rand_scores_pck\n",
    "sc_pck_fit_G1 = rand_scores_pck_fit\n",
    "\n",
    "# unpack them\n",
    "sc_G1, sc_diag_G1 = sc_pck_G1\n",
    "sc_G2, sc_diag_G2 = sc_pck_G1\n",
    "sc_G3, sc_diag_G3 = sc_pck_G1\n",
    "sc_G4, sc_diag_G4 = sc_pck_G1\n",
    "\n",
    "sc_fit_G1, sc_fit_diag_G1 = sc_pck_fit_G1\n",
    "sc_fit_G2, sc_fit_diag_G2 = sc_pck_fit_G1\n",
    "sc_fit_G3, sc_fit_diag_G3 = sc_pck_fit_G1\n",
    "sc_fit_G4, sc_fit_diag_G4 = sc_pck_fit_G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 226, 226)\n",
      "(4, 5, 226, 226)\n",
      "sc_diag_G1 (5, 226)\n",
      "avg_diag_sc (4, 5, 226)\n"
     ]
    }
   ],
   "source": [
    "sc_G1=np.asarray(sc_G1)\n",
    "sc_G2=np.asarray(sc_G2)\n",
    "sc_G3=np.asarray(sc_G3)\n",
    "sc_G4=np.asarray(sc_G4)\n",
    "\n",
    "sc_diag_G1=np.asarray(sc_diag_G1)\n",
    "sc_diag_G2=np.asarray(sc_diag_G2)\n",
    "sc_diag_G3=np.asarray(sc_diag_G3)\n",
    "sc_diag_G4=np.asarray(sc_diag_G4)\n",
    "\n",
    "sc_fit_G1=np.asarray(sc_fit_G1)\n",
    "sc_fit_G2=np.asarray(sc_fit_G2)\n",
    "sc_fit_G3=np.asarray(sc_fit_G3)\n",
    "sc_fit_G4=np.asarray(sc_fit_G4)\n",
    "\n",
    "\n",
    "sc_fit_diag_G1=np.asarray(sc_fit_diag_G1)\n",
    "sc_fit_diag_G2=np.asarray(sc_fit_diag_G2)\n",
    "sc_fit_diag_G3=np.asarray(sc_fit_diag_G3)\n",
    "sc_fit_diag_G4=np.asarray(sc_fit_diag_G4)\n",
    "\n",
    "\n",
    "avg_sc= np.zeros([4, args.loop_null_iter, sc_G1.shape[1], sc_G1.shape[2]])\n",
    "avg_sc[0,:,:,:] = sc_G1\n",
    "avg_sc[1,:,:,:] = sc_G2\n",
    "avg_sc[2,:,:,:] = sc_G3\n",
    "avg_sc[3,:,:,:] = sc_G4\n",
    "avg_sc = np.mean(avg_sc, axis=0)\n",
    "\n",
    "avg_diag_sc= np.zeros([4, args.loop_null_iter, sc_diag_G1.shape[1]])\n",
    "avg_diag_sc[0,:,:]=sc_diag_G1\n",
    "avg_diag_sc[1,:,:]=sc_diag_G2\n",
    "avg_diag_sc[2,:,:]=sc_diag_G3\n",
    "avg_diag_sc[3,:,:]=sc_diag_G4\n",
    "avg_diag_sc = np.mean(avg_diag_sc, axis=0)\n",
    "\n",
    "#------ save fit results (no cross validation)\n",
    "avg_sc_fit= np.zeros([4, args.loop_null_iter, sc_fit_G1.shape[1], sc_fit_G1.shape[2]])\n",
    "avg_sc_fit[0,:,:,:] = sc_fit_G1\n",
    "avg_sc_fit[1,:,:,:] = sc_fit_G2\n",
    "avg_sc_fit[2,:,:,:] = sc_fit_G3\n",
    "avg_sc_fit[3,:,:,:] = sc_fit_G4\n",
    "avg_sc_fit = np.mean(avg_sc_fit, axis=0)\n",
    "\n",
    "avg_diag_sc_fir= np.zeros([4, args.loop_null_iter, sc_fit_diag_G1.shape[1]])\n",
    "avg_diag_sc_fir[0,:,:]=sc_fit_diag_G1\n",
    "avg_diag_sc_fir[1,:,:]=sc_fit_diag_G2\n",
    "avg_diag_sc_fir[2,:,:]=sc_fit_diag_G3\n",
    "avg_diag_sc_fir[3,:,:]=sc_fit_diag_G4\n",
    "avg_diag_sc_fir = np.mean(avg_diag_sc_fir, axis=0)\n",
    "\n",
    "# ------ Pack all scores and save them\n",
    "sc_subj_pck = [avg_sc, avg_diag_sc, avg_sc_fit, avg_diag_sc_fir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearnigEEG",
   "language": "python",
   "name": "deeplearnigeeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
